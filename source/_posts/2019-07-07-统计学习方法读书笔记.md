---
title: 统计学习方法读书笔记
date: 2019-07-07 19:58:43
categories: 机器学习
tags: [机器学习,统计学习方法]
description: 《统计学习方法》读书笔记
mathjax: true
---

[TOC]

# 资料

[统计学习方法读书笔记](https://www.cnblogs.com/limitlessun/p/8611103.html)

[代码实现](https://github.com/fengdu78/lihang-code)

[笔记](https://github.com/SmirkCao/Lihang)

# CH1：统计学习方法概论

## 实现统计学习方法的步骤

统计学习方法三要素：模型，策略，算法

> 1. 得到一个有限的训练数据集合；
> 2. 确定包含所有可能的模型的**假设空间**，即学习模型的集合；
> 3. 确定模型选择的准则，即学习的**策略**；
> 4. 实现求解最优模型的算法，即学习的**算法**；
> 5. 通过学习方法选择最优的模型；
> 6. 利用学习的最优模型对新数据进行预测或分析。

## 统计学习分类

### 基本分类

- 监督学习：采用的数据集包含标签，如KNN
- 无监督学习：采用的数据集不包含标签，如k-means
- 半监督学习：监督学习与与无监督学习的结合
- 强化学习：通过接收环境对动作的奖励（反馈）获得学习信息并更新模型参数

### 按模型分类

- 概率模型：为生成模型
- 非概率模型：为判别模型

### 按算法分类

- 在线学习
- 批量学习

## 统计学习方法三要素

### 模型

在监督学习过程中，模型就是所要学习的**条件概率分布**或者**决策函数**。

|              | 假设空间$\cal F$                                             | 输入空间$\cal X$ | 输出空间$\cal Y$ | 参数空间      |
| ------------ | ------------------------------------------------------------ | ---------------- | ---------------- | ------------- |
| 决策函数     | $\cal F\it =\{f_{\theta} |Y=f_{\theta}(x), \theta \in \bf R \it ^n\}$ | 变量             | 变量             | $\bf R\it ^n$ |
| 条件概率分布 | $\cal F\it =\{P|P_{\theta}(Y|X),\theta\in \bf R \it ^n\}$    | 随机变量         | 随机变量         | $\bf R\it ^n$ |

### 策略

学习过程或选择最优的模型的过程所参照的准则。

#### 损失函数与风险函数

> **损失函数**度量模型**一次预测**的好坏，**风险函数**度量**平均意义**下模型预测的好坏。

1. 损失函数(loss function)或代价函数(cost function)
   损失函数定义为给定输入$X$的**预测值$f(X)$**和**真实值$Y$**之间的**非负实值**函数，记作$L(Y,f(X))$

2. 风险函数(risk function)或期望损失(expected loss)
   这个和模型的泛化误差的形式是一样的

$$
R_{exp}(f)=E_p[L(Y, f(X))]=\int_{\mathcal X\times\mathcal Y}L(y,f(x))P(x,y)\, {\rm d}x{\rm d}y模型$f(X)$关于联合分布$P(X,Y)$的**平均意义下的**损失(**期望**损失)，但是因为$P(X,Y)$是未知的，所以前面的用词是**期望**，以及**平均意义下的**。
$$

模型$f(X)$关于联合分布$P(X,Y)$的**平均意义下的**损失(**期望**损失)，但是因为$P(X,Y)$是未知的，所以前面的用词是**期望**，以及**平均意义下的**。

这个表示其实就是损失的均值，反映了对整个数据的预测效果的好坏，$P(x,y)$转换成$\frac {\nu(X=x, Y=y)}{N}$更容易直观理解。

3. **经验风险**(empirical risk)或**经验损失**(empirical loss)
   $R_{emp}(f)=\frac{1}{N}\sum^{N}_{i=1}L(y_i,f(x_i))$
   模型$f$关于**训练样本集**的平均损失
   根据大数定律，当样本容量N趋于无穷大时，经验风险趋于期望风险

4. **结构风险**(structural risk)
   $R_{srm}(f)=\frac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i))+\lambda J(f)$
   $J(f)$为模型复杂度, $\lambda \geqslant 0$是系数，用以权衡经验风险和模型复杂度。

#### 常用损失函数

损失函数数值越小，模型就越好

1. 0-1损失
   $$
   L(Y,f(X))=\begin{cases}1, Y \neq f(X) \\0, Y=f(X) \end{cases}
   $$
   
2. 平方损失
   $$
   L(Y,f(X))=(Y-f(X))^2
   $$
   
3. 绝对损失

$$
L(Y,f(X))=|Y-f(X)|
$$

4. 对数损失
   这里$P(Y|X)\leqslant 1$，对应的对数是负值，所以对数损失中包含一个负号。

$$
L(Y,P(Y|X))=-\log P(Y|X)
$$



#### ERM与SRM

经验风险最小化(Empirical Risk Minimization,ERM)与结构风险最小化(Structural Risk Minimization,SRM)

1. **极大似然估计**是经验风险最小化的一个例子
   当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化等价于极大似然估计
2. **贝叶斯估计**中的**最大后验概率估计**是结构风险最小化的一个例子
   当模型是条件概率分布，损失函数是对数损失函数，**模型复杂度由模型的先验概率表示**时，结构风险最小化等价于最大后验概率估计

### 算法

这章里面简单提了一下，具体可以参考[CH12](../CH12/README.md)表格中关于学习算法的描述。

## 